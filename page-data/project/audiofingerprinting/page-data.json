{
    "componentChunkName": "component---src-templates-projects-page-js",
    "path": "/project/audiofingerprinting",
    "result": {"data":{"projects":{"report":{"content":"## ABSTRACT\nRecognizing a song from a large cluster of audio can't be achieved by using brute force to compare an audio sample to every song in the database. In this project we use hashing,a process in which reproducible hash tokens are extracted to save the effort, this method compares the hash values instead of the whole ﬁles so that it will be more efficient, Audio fingerprinting is the process of representing an audio signal in a compact way by extracting relevant features of the audio content.The fingerprints from the unknown sample are matched against a large set of fingerprints stored in the database. In this our model we are using mysql as the database.Companies like shazam, phillips, intrasonics and many more use audio fingerprinting for various implementations.\n\n## AUDIO RECOGNITION\n\nRead the audio file recorded and store it into a 2-D array of amplitude against time.The recording can be done using the microphone or the input file can be read from the system itself and saved as an audio file.This process is same for both , adding the audio files to the database as well as for recognising the audio files i.e both training and testing phase.\n\n![ampvstime.png](https://res.cloudinary.com/iet-nitk/image/upload/v1649261524/ampvstime_b48d6a4506.png)\n## Fast Fourier Transform (FFT)\n\n\nNow we use Fast Fourier Transform (FFT) to change the waveform to frequency domain from time domain.\n\n![ampvsfreq.png](https://res.cloudinary.com/iet-nitk/image/upload/v1649261524/ampvsfreq_24e789b891.png)\n\n## Spectrogram\n\nNext step is to perform Short-Term Fourier Transform (STFT) of the audio signal by breaking down the signal into small chunks and performing the Fourier Transform on each of them to generate the spectrogram, which is a visual plot of all three variables amplitude against time and frequency.\n\n\n![specto.png](https://res.cloudinary.com/iet-nitk/image/upload/v1649261526/specto_da663c50b0.png)\n\n## Mapping peaks\n\nThe processing is usually carried out on a 2-D array , which stores the STFT coefficients of the file and the peaks, local maxima points of the file, which are mapped by masking.A set of the peak and its neighbour are passed to a hash function to generate a hash. A hash is an encoded string which is unique for each input. An audio fingerprint is generated which is a set of hash values and the offset value(time component of the peak).This value is stored in the database with a unique song_id.\nAfter we perform these steps on the known file we can match the audio file.\n\n## Recognise the song\n\nWe recognise the song by comparing the hash value from the database.A pair of key-value is appended into an empty dictionary created for each song. Where key is the difference between the database offset and the sample offset and value if the number of repetitions of the matches we get while comparing the hash values.\nA score is calculated for each song which is the maximum value of ‘value’ in that particular dictionary.\nThe song with maximum score is the best match for the input file and the model returns the song name with the score value.\n\n## Conclusion\n\nThe model has been successful in recognizing the song by finding the fingerprints.\nThe further improvements for this model would be to use noise filter techniques, get accurate fingerprints and improve the database.\n\n## RESOURCES\n\n- https://medium.com/swlh/understanding-audio-fingerprinting-b39682aa3b5f\n- https://ourcodeworld.com/articles/read/973/creating-your-own-shazam-identify-songs-with-python-through-audio-fingerprinting-in-ubuntu-18-04","date":"April 6th, 2022"},"authors":[{"name":"K Snehith Bhagavan"},{"name":"Attada Ramprasad"},{"name":"Sharuf Baig"},{"name":"Pooja Gayathri Kanala"}],"sig":{"name":"Cipher","logo":{"localFile":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAADuklEQVQ4y4WTX0xbVRzHf7dl2CVLe++599z2XPonXIq9rBuDJaJzZiZzySTzQX0yxhhjorGYiQxTlUeGiVl0m0nniDBFEtZ/t72FtrSVMYajrQyYgErLAyGrbyS4vbGExGvOTXjRME9y7p/f73s/53vO73cB/jVm78xCNpOBaCQC8VgcinNF89bWlmlnZ4cpFUvmcS0FdBZyeZjMTsL/jvxkzgDGojGmra0NVpaXQdd1Y/6++hu8/eZbkIirDNXc+mkKdnd394dpiSSosTgkEwnm+rVvachUmit2rf2xlqpWKulfSuWg36dYvh++QbUm6jQRV58ATGrUGXzSc4G+1s3emc3Mz8/ro6Oj+sjIiF4ul/XK2trCx+c/sl3+6msKZeKx2P7AifFxWFxYNK9Xq7Bw717/3Z/v6n19fX8VCoXHMzMz+sDAwOPp6Wl9cWFxcHt7G2oPHpgSamJ/IE2e/+BDOKr46+8vLQ1d/ebqo2KxqFcr1V9XV1aX1tfXdVVVa+VSKfJ58NNDX/QPgJZMPgEYVyGV1ODHH0ZwNp15LxAIZCqVip6ZSK+Ex27ef/Twob6xsbE69N1QdyGXt6cn0pDStP2ByUTSqObYzTEmm868GwwGQ4ODg/rm5ubff9Zqejgc1ru7u0ez6cz70UjkYD6Xg/9s2eVygdPlBFmWIRqOUAFDKx0NR7y3pqbODg8P10KhkN7V1ZUJBAI3stnsK7FozGt0RFxlqAFFUQwjl768BIAxBixiYFmWQQgZgov9F03XQ9eMtllZXtaKc3NbVy5f+Sylae+ocdWVz+XhQk+PmWqtVqvxLcdxQCfY7XaQJEKDwCEOrDarEaPivZFKak/fnr59vJAvsL29vUaMYzmwPGXZAxowegdB4EHgeer0iCiKR1mOrSOEcFKDVC9J0hGMsWfvTwEA83MnTtSLokgcDoff6/UewBg7CSGKIPAs3S0ghCjMZ7PZjhNCJIwxttlsz8iyfAghdJbn+Tf8fj8FnEMIvS41NIgIodMY45c7OztNCKFWhNCrCKFneZ4HoBdRFBs4jntRFPExjAXEsuwxQggihJxqbW21EEKsGOMXWJY95Xa7earlef41B3EcFAShnRByWhRFj+HQ4bADIYSemyCKouhTfNDS0nJAURRzR0eHiXaBoiimvTN96cwZplFutDQ3NyOfz1cny3IdjR8+3FLf1NQERoUdDodRbUEQwOv1gsfjAZpsbGwEp9PJ0Of29najtZ4/eRLs1IREwO12gyRJxkI0Rxf/B4rXfsh+0HulAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/c5844ab334a4a1435ef1970a20dae837/cb49a/Cipher_ddb0d04e8e.png","srcSet":"/static/c5844ab334a4a1435ef1970a20dae837/2e8c6/Cipher_ddb0d04e8e.png 50w,\n/static/c5844ab334a4a1435ef1970a20dae837/bdcb3/Cipher_ddb0d04e8e.png 100w,\n/static/c5844ab334a4a1435ef1970a20dae837/cb49a/Cipher_ddb0d04e8e.png 200w,\n/static/c5844ab334a4a1435ef1970a20dae837/1950a/Cipher_ddb0d04e8e.png 400w","sizes":"(min-width: 200px) 200px, 100vw"},"sources":[{"srcSet":"/static/c5844ab334a4a1435ef1970a20dae837/b90ba/Cipher_ddb0d04e8e.webp 50w,\n/static/c5844ab334a4a1435ef1970a20dae837/d67c1/Cipher_ddb0d04e8e.webp 100w,\n/static/c5844ab334a4a1435ef1970a20dae837/923ce/Cipher_ddb0d04e8e.webp 200w,\n/static/c5844ab334a4a1435ef1970a20dae837/33402/Cipher_ddb0d04e8e.webp 400w","type":"image/webp","sizes":"(min-width: 200px) 200px, 100vw"}]},"width":200,"height":160}}}}},"url":"https://github.com/IET-NITK/AudioFingerprinting","title":"Audio Fingerprinting","description":"An Audio fingerprint is a collection of the hash tags, or\nsignatures, of a song’s samples. They measure which\nfrequencies in each sample are the strongest frequencies in\neach sample. These audio fingerprint helps to identify the\nsong from the database.","ongoing":false}},"pageContext":{"pathSlug":"Audio Fingerprinting","sig":null,"date":"2022-04-07T08:05:38.472Z"}},
    "staticQueryHashes": ["1681770253","3546218355","362689041","4192044320"]}